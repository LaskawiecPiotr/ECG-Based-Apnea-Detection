{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63cb6b-0dcb-42bc-9388-2ab0ede1e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ECG Signal Processing and Feature Extraction for Apnea Detection\n",
    "# =============================================================================\n",
    "# - This script processes ECG signals from the Apnea ECG dataset.\n",
    "# - It splits the signal into 120-second intervals (similar procedures can be\n",
    "#   done for 60s and 90s intervals).\n",
    "# - It cleans the data by removing segments with poor signal quality,\n",
    "#   extracts HRV features using (a slightly modified) NeuroKit2 package, and saves the processed data.\n",
    "# - Original ECG data can be downloaded from:\n",
    "#   https://physionet.org/content/apnea-ecg/1.0.0/\n",
    "#\n",
    "# Usage:\n",
    "# - Ensure the required packages are installed (see requirements.txt).\n",
    "# - Update the file paths (e.g., \"C:\\Users\\piotr\\Desktop\\PSG data\\Apnea ECG\\\")\n",
    "#   to match your system.\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c26d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below if you need to install dependencies.\n",
    "# %pip install -r requirements.txt \n",
    "# ----------------------------\n",
    "# Import Required Libraries\n",
    "# ----------------------------\n",
    "# We import all necessary libraries\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e22a5d2e-bba6-4be8-9f89-af2204c77b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_creation(record_path):\n",
    "    \"\"\"\n",
    "    Process an ECG record for apnea detection.\n",
    "    \n",
    "    Parameters:\n",
    "        record_path (str): Path to the ECG record (without file extension).\n",
    "    \n",
    "    Returns:\n",
    "        features (np.array): Extracted HRV features for each segment.\n",
    "        labels (np.array): Corresponding labels (0 for no apnea, 1 for apnea).\n",
    "    \"\"\"\n",
    "    # Read annotations (apnea markers) from the record.\n",
    "    annotation = wfdb.rdann(record_path, extension='apn')\n",
    "    \n",
    "    # Get the sampling frequency\n",
    "    sampling_rate = wfdb.rdrecord(record_path).fs  \n",
    "    \n",
    "    # Get annotation times in seconds\n",
    "    annotation_times = np.array(annotation.sample) / sampling_rate  \n",
    "    \n",
    "    # Map annotation symbols: \"N\" indicates no apnea (0), others indicate apnea (1)\n",
    "    annotation_labels = np.where(np.array(annotation.symbol)==\"N\",0, 1).astype(np.int32)\n",
    "    # Get the signal\n",
    "    signal,dic = wfdb.rdsamp(record_path)\n",
    "    signal=signal.flatten()\n",
    "    # Discard the first and last annotation\n",
    "    annotation_times = annotation_times[1:-1]  \n",
    "    annotation_labels = annotation_labels[1:-1]\n",
    "    df=pd.DataFrame()\n",
    "    # Keep track of indices of poor-quality segments.\n",
    "    bad_times=[]\n",
    "    # Process each annotation segment.\n",
    "    for i in range(len(annotation_times)):\n",
    "        try:\n",
    "            # Define the window: 60 seconds before and after the annotation time and clean it.\n",
    "            time=int(annotation_times[i])*sampling_rate\n",
    "            clean = nk.ecg_clean(signal[time-60*sampling_rate:time+60*sampling_rate], sampling_rate=sampling_rate)\n",
    "            \n",
    "            # Evaluate ECG quality (mean quality score).\n",
    "            quality = np.mean(nk.ecg_quality(clean, sampling_rate=sampling_rate))\n",
    "            \n",
    "            if quality < 0.5:\n",
    "                bad_times.append(i)  # Mark as bad quality\n",
    "                print(f\"Warning: ECG quality check failed at index {i}. Marking as bad data\")\n",
    "            else:\n",
    "                # Extract features from cleaned ECG\n",
    "                peaks = nk.ecg_peaks(clean, sampling_rate=sampling_rate)\n",
    "                features = nk.hrv(peaks[0], sampling_rate=sampling_rate)  \n",
    "                df = pd.concat([df, features])\n",
    "        except Exception as e:\n",
    "            # If any error occurs, consider this segment as bad\n",
    "            bad_times.append(i)\n",
    "            print(f\"Warning: ECG quality check failed at index {i}. Marking as bad data. Error: {e}\")\n",
    "    # Convert features to a NumPy array.\n",
    "    features= df.to_numpy()\n",
    "    # Remove labels corresponding to bad segments.\n",
    "    labels=np.delete(annotation_labels,bad_times)\n",
    "    return features,labels\n",
    "\n",
    "def clean_features(features, labels):\n",
    "    \"\"\"\n",
    "    Remove columns containing only NaNs. Then, remove rows that contain a NaN.\n",
    "    \"\"\"\n",
    "    features[np.isinf(features)] = np.nan\n",
    "    nan_cols = np.all(np.isnan(features), axis=0)\n",
    "    clean_features = features[:, ~nan_cols]\n",
    "    nan_rows = np.isnan(clean_features).any(axis=1)\n",
    "    nan_indexes = np.where(nan_rows)[0]\n",
    "    features_cleaned = clean_features[~nan_rows]\n",
    "    labels_cleaned = np.delete(labels, nan_indexes)\n",
    "    return features_cleaned, labels_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7b433-22fe-4b17-ad39-ffa7aeb9f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each patient we extract the whole signal, split it into 120s intervals and extract features. This is for the training data.\n",
    "list_of_features_train=[]\n",
    "list_of_labels_train=[]\n",
    "list_of_file_names=open(r\"Extracted Features and supplemental files\\list_train\").read().split(\"\\n\")\n",
    "for i in list_of_file_names:\n",
    "    # You need to change the record_path to match where your Apnea ECG data set is.\n",
    "    record_path=fr\"C:\\Users\\piotr\\Desktop\\PSG data\\Apnea ECG\\{i}\"\n",
    "    features,labels = data_creation(record_path)\n",
    "    list_of_features_train.append(features)\n",
    "    list_of_labels_train.append(labels)\n",
    "extracted_features_train=np.concatenate(list_of_features_train)\n",
    "extracted_labels_train=np.concatenate(list_of_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affeccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the training features.\n",
    "features_cleaned_train, labels_cleaned_train= clean_features(extracted_features_train, extracted_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429034d6-f854-47a8-8530-6dadbbbca381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed training data.\n",
    "np.save(\"features_cleaned_120s_train\",features_cleaned_train)\n",
    "np.save(\"labels_cleaned_120s_train\",labels_cleaned_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52afac-c0f2-4a33-bf37-2e1613ac5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We repeat the whole procedure for the testing data.\n",
    "list_of_features_test=[]\n",
    "list_of_labels_test=[]\n",
    "list_of_file_names=open(r\"Extracted Features and supplemental files\\list_test\").read().split(\"\\n\")\n",
    "for i in list_of_file_names:\n",
    "    # You will need to change the record path to where the Apnea ECG data set is located.\n",
    "    record_path=fr\"C:\\Users\\piotr\\Desktop\\PSG data\\Apnea ECG\\{i}\"\n",
    "    features,labels = data_creation(record_path)\n",
    "    list_of_features_test.append(features)\n",
    "    list_of_labels_test.append(labels)\n",
    "extracted_features_test=np.concatenate(list_of_features_test)\n",
    "extracted_labels_test=np.concatenate(list_of_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458c769-4514-4cf9-b223-5e36b128142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaned_test, labels_cleaned_test = clean_features(extracted_features_test, extracted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403070f-231a-4af5-9fee-23840375d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"features_cleaned_120s_test\",features_cleaned_test)\n",
    "np.save(\"labels_cleaned_120s_test\",labels_cleaned_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration: simulate an ECG signal to obtain HRV feature names.\n",
    "signal = nk.ecg_simulate(duration=120, sampling_rate=100)\n",
    "peaks = nk.ecg_peaks(signal, sampling_rate=100)\n",
    "features = nk.hrv(peaks[0], sampling_rate=100)\n",
    "# Only keep feature names that do not have any missing values.\n",
    "features_names = features.columns[~features.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f43995e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Feature Names\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(features_names, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e41046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
